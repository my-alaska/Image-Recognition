{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matplotlib.colors.Normalize(vmin=-1, vmax=1, clip=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d45ee310481d9578"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(cuda_id)\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "228b229f364850cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Discriminator and Generator model classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cda7a783cf3bac4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.network(img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "605d15e4ec16b7cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.reshape(input, self.shape)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(64, 1024),\n",
    "            Reshape((-1, 64, 4, 4)),\n",
    "            nn.ConvTranspose2d(64, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 3, 5, 1, 2, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.network(img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d76cb63256264c9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# return a vector of n samples from N(0,1) distribution\n",
    "get_normal = lambda shape: torch.normal(torch.zeros(shape), 1).to(device)\n",
    "normal_vector = get_normal(64)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfb2223e31a38c83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "forwarded_random_image = generator.forward(normal_vector)\n",
    "forwarded_random_image.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d144337cc5d233ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scale_and_display(image, normalize=False, size=8):\n",
    "    if normalize:\n",
    "        value_range = (image.min(), image.max())\n",
    "    else:\n",
    "        value_range = (-1, 1)\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(\n",
    "        (\n",
    "            vutils.make_grid(\n",
    "                image, nrow=4, padding=2, normalize=True, value_range=value_range\n",
    "            )\n",
    "            .permute(1, 2, 0)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "    )\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e6244a0336ff6d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_and_display(torch.clone(forwarded_random_image).cpu())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a1008a9f1ca9b8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_and_display(forwarded_random_image, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d649996a856c9d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's ensure that the Discriminator doesn't throw any obvious errors\n",
    "discriminator = Discriminator().to(device)\n",
    "discriminator.forward(forwarded_random_image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffd7e82c43e408e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d8882fe64c3f12f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lambda_scaling(tensor):\n",
    "    return tensor * 2 - 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d24dcc59d7bd04ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = dset.ImageFolder(\n",
    "    root=\"./imgs\",\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda_scaling),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51e3277faf08ed13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = torch.stack([element[0] for element in data_dir]).to(device)\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f59f8354b157a3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_and_display(torch.clone(data[2]).cpu())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36dbaddb06161d5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[0].shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b920f07893acf134"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example of training a non-standard model in a loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "875becb6d215ad2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class NonstandardModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NonstandardModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(10, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.network(img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14364bbd1d6c7808"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_model = NonstandardModel().to(device)\n",
    "for i, param in enumerate(my_model.parameters()):\n",
    "    if not i in {0, 3}:  # 0 and 3 correspond to the first 2 fully connected layers\n",
    "        param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c2bdffa626a931"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copy model parameters to compare them at the end\n",
    "reference_list = []\n",
    "for p in my_model.parameters():\n",
    "    reference_list.append(torch.clone(p))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d452399384bcf36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch = torch.stack([get_normal(10) for _ in range(10)])\n",
    "optimizer = torch.optim.SGD(\n",
    "    my_model.parameters(), lr=0.001, momentum=0.9, nesterov=True\n",
    ")\n",
    "for epoch in range(1000):\n",
    "    y_pred = my_model(batch)\n",
    "    loss = 42 - 42 * y_pred.mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(loss)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5c30e0cb8258c69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for p in my_model.parameters():\n",
    "    result_list.append(p)\n",
    "\n",
    "for ref, res in zip(reference_list, result_list):\n",
    "    print((ref - res).sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80d0f7ae6fceb80e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The basic idea of discriminator training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11e1689a076e5835"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8310da4f65021ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_batch = data[:BATCH_SIZE]\n",
    "real_labels = torch.ones(BATCH_SIZE) + torch.rand(BATCH_SIZE) * 0.05\n",
    "\n",
    "generated_batch = generator.forward(\n",
    "    torch.stack([get_normal(64) for _ in range(BATCH_SIZE)])\n",
    ")\n",
    "generated_labels = torch.zeros(BATCH_SIZE) - torch.rand(BATCH_SIZE) * 0.05\n",
    "\n",
    "batch = torch.concat([real_batch, generated_batch])\n",
    "labels = torch.concat([real_labels, generated_labels])\n",
    "labels = labels.clip(min=0, max=1).reshape((-1, 1)).to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aee52e9073d6737"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discriminator_opt = torch.optim.Adam(discriminator.parameters(), lr=0.00001)\n",
    "loss_function = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4c1879d07868279"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = discriminator(batch)\n",
    "loss = loss_function(y_pred, labels)\n",
    "\n",
    "discriminator_opt.zero_grad()\n",
    "loss.backward()\n",
    "discriminator_opt.step()\n",
    "\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2502c3e58e440c94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The basic idea of generator training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9577f6d5f1d2b49e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch = torch.stack([get_normal(64) for _ in range(BATCH_SIZE)])\n",
    "labels = torch.ones(BATCH_SIZE)\n",
    "labels = labels.clip(max=1).reshape((-1, 1)).to(device)\n",
    "\n",
    "generator_opt = torch.optim.Adam(generator.parameters(), lr=0.00001)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44df473123c60e16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = generator(batch)\n",
    "y_pred = discriminator(images)\n",
    "loss = loss_function(y_pred, labels)\n",
    "generator_opt.zero_grad()\n",
    "loss.backward()\n",
    "generator_opt.step()\n",
    "\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ad45450f649c0c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc6f6c77819a4007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_full_batches = data.shape[0] // BATCH_SIZE\n",
    "n_ending_elems = data.shape[0] % BATCH_SIZE\n",
    "batches = [\n",
    "    data[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] for i in range(n_full_batches)\n",
    "] + [data[-n_ending_elems:]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e13cdfb05986070"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53cb5d38a2058a02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_state(dis, gen, dis_opt, gen_opt, path, epoch):\n",
    "    torch.save(dis, path + \"/discriminator\" + str(epoch))\n",
    "    torch.save(gen, path + \"/generator\" + str(epoch))\n",
    "    torch.save(dis_opt, path + \"/discriminator_optimizer\" + str(epoch))\n",
    "    torch.save(gen_opt, path + \"/generator_optimizer\" + str(epoch))\n",
    "\n",
    "\n",
    "def load_state(path, epoch):\n",
    "    dis = torch.load(path + \"/discriminator\" + str(epoch))\n",
    "    gen = torch.load(path + \"/generator\" + str(epoch))\n",
    "    dis_opt = torch.load(path + \"/discriminator_optimizer\" + str(epoch))\n",
    "    gen_opt = torch.load(path + \"/generator_optimizer\" + str(epoch))\n",
    "    return dis, gen, dis_opt, gen_opt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86c080058372e1c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "constant_for_comparison = torch.stack([get_normal(64) for _ in range(16)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "892775b3cab508a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "discriminator_opt = torch.optim.Adam(\n",
    "    discriminator.parameters(), lr=0.00001, weight_decay=0.01\n",
    ")\n",
    "generator_opt = torch.optim.Adam(generator.parameters(), lr=0.00001)\n",
    "loss_function = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f20f85603c7cda29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_loss = []\n",
    "for epoch in range(3000):\n",
    "    dis_cum_loss = 0\n",
    "    gen_cum_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch_size = batch.shape[0]\n",
    "\n",
    "        # Training discriminator to recognise real images+\n",
    "        true_labels = torch.ones(batch_size) - torch.rand(batch_size) * 0.05\n",
    "        dis_pred_for_true = discriminator(batch)\n",
    "\n",
    "        # Training discriminator to recognise fakes\n",
    "        generated_batch = generator.forward(get_normal((batch_size, 64)))\n",
    "        false_labels = torch.zeros(batch_size) + torch.rand(batch_size) * 0.05\n",
    "        dis_pred_for_false = discriminator(generated_batch)\n",
    "\n",
    "        dis_loss = loss_function(\n",
    "            torch.concat([dis_pred_for_true, dis_pred_for_false]),\n",
    "            torch.concat([true_labels, false_labels]).reshape((-1, 1)).to(device),\n",
    "        )\n",
    "        discriminator_opt.zero_grad()\n",
    "        dis_cum_loss += dis_loss\n",
    "        dis_loss.backward()\n",
    "        discriminator_opt.step()\n",
    "\n",
    "        # Training generator\n",
    "        gen_labels = torch.ones(batch_size)\n",
    "        gen_labels = gen_labels.reshape((-1, 1)).to(device)\n",
    "        gen_batch = generator(get_normal((batch_size, 64)))\n",
    "        gen_pred = discriminator(gen_batch)\n",
    "        gen_loss = loss_function(gen_pred, gen_labels)\n",
    "        generator_opt.zero_grad()\n",
    "        gen_cum_loss += gen_loss\n",
    "        gen_loss.backward()\n",
    "        generator_opt.step()\n",
    "\n",
    "    if epoch % 50 == 0 and epoch > 0:\n",
    "        epoch_loss.append((dis_cum_loss, gen_cum_loss))\n",
    "        save_state(\n",
    "            discriminator,\n",
    "            generator,\n",
    "            discriminator_opt,\n",
    "            generator_opt,\n",
    "            \"./saved_models\",\n",
    "            epoch,\n",
    "        )\n",
    "        print(\"epoch: \", epoch)\n",
    "        print(\"d loss: \", dis_cum_loss / len(batches))\n",
    "        print(\"g loss: \", gen_cum_loss / len(batches))\n",
    "        images = generator.forward(constant_for_comparison)\n",
    "        scale_and_display(images.cpu(), normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9bbbc27920df9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b33783aa8fc05ed0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses = [i.cpu().detach().numpy() for i, j in epoch_loss], [\n",
    "    j.cpu().detach().numpy() for i, j in epoch_loss\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afba5c16d48dc73f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "\n",
    "ax1.plot(losses[0], label=\"discriminator loss\")\n",
    "ax1.plot(losses[1], label=\"generator loss\")\n",
    "ax1.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e670846253f12072"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recreating training data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0f51ac13442c4f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale_and_display(data[2], size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d53982a1fdda9f1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reference_image = data[2]\n",
    "input1 = get_normal(64)\n",
    "input1.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.SGD([input1], 0.01, momentum=0.9, nesterov=True)\n",
    "loss_function_MSE = nn.MSELoss()\n",
    "\n",
    "generated_image = generator(input1)\n",
    "scale_and_display(generated_image, size=4)\n",
    "for i in range(1000):\n",
    "    generated_image = generator(input1)\n",
    "    loss = loss_function_MSE(generated_image, reference_image)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "scale_and_display(generator(input1), size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "801c7022b9ef82a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manually modifying the input vector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e17bdd4af19a01ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's see how the image will change if we manually modify the vector\n",
    "modified_input = torch.clone(input1)\n",
    "indices = [2 * i for i in range(32)]\n",
    "modified_input[indices] = 0.5\n",
    "scale_and_display(generator(modified_input), size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b66a795a74162b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attempt to generate an image from outside of training data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "149350517154ce38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rat_dir = dset.ImageFolder(\n",
    "    root=\"./szczoor\",\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(32),\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda_scaling),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "rat = torch.stack([element[0] for element in rat_dir]).to(device)\n",
    "scale_and_display(rat, size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11b985eb481108f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input2 = get_normal(64)\n",
    "input2.requires_grad = True\n",
    "optimizer = torch.optim.SGD([input2], 0.1, momentum=0.9, nesterov=True)\n",
    "loss_function_MSE = nn.MSELoss()\n",
    "\n",
    "generated_image = generator(input2)\n",
    "scale_and_display(generated_image, size=4)\n",
    "for i in range(1000):\n",
    "    generated_image = generator(input2)\n",
    "    loss = loss_function_MSE(generated_image, rat)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "scale_and_display(generator(input2), size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d0789aa73355bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating data transition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c8bb320ae7fc2b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reference_image = data[3]\n",
    "input3 = get_normal(64)\n",
    "input3.requires_grad = True\n",
    "scale_and_display(reference_image, size=4)\n",
    "\n",
    "optimizer = torch.optim.SGD([input3], 0.01, momentum=0.9, nesterov=True)\n",
    "loss_function_MSE = nn.MSELoss()\n",
    "\n",
    "generated_image = generator(input3)\n",
    "scale_and_display(generated_image, size=4)\n",
    "for i in range(1000):\n",
    "    generated_image = generator(input3)\n",
    "    loss = loss_function_MSE(generated_image, reference_image)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "scale_and_display(generator(input3), size=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb059c2992dcad7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distance_vect = input3 - input1\n",
    "\n",
    "for i in range(6):\n",
    "    generated_image = generator(input1 + distance_vect * i / 5)\n",
    "    scale_and_display(generated_image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "269d6264e7340ec5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7d50d14815d64435"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
