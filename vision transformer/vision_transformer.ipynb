{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:06.063975900Z",
     "start_time": "2023-11-27T23:30:04.863699400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(cuda_id)\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:06.105974400Z",
     "start_time": "2023-11-27T23:30:06.084974900Z"
    }
   },
   "id": "e8a100858fc8b50b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download and preparethe data\n",
    "\n",
    "We'll use the CIFAR10 dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f51fdad69ce1e7a6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:06.461974100Z",
     "start_time": "2023-11-27T23:30:06.095975400Z"
    }
   },
   "id": "86e29a36b84c2248"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:06.477974100Z",
     "start_time": "2023-11-27T23:30:06.461974100Z"
    }
   },
   "id": "bf8b0e5f6d01c396"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# download and augment the training dataset\n",
    "if not os.path.exists(\"./data\"):\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "data = CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomResizedCrop(size=32, ratio=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0, 1),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0, 1),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "test_loader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:07.583229500Z",
     "start_time": "2023-11-27T23:30:06.479974200Z"
    }
   },
   "id": "8ddb240309e17171"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['airplane',\n 'automobile',\n 'bird',\n 'cat',\n 'deer',\n 'dog',\n 'frog',\n 'horse',\n 'ship',\n 'truck']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = data.classes\n",
    "classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:07.600228700Z",
     "start_time": "2023-11-27T23:30:07.578229400Z"
    }
   },
   "id": "a2cc10088ac10168"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print out an example image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2277894ab71e829"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:07.881982500Z",
     "start_time": "2023-11-27T23:30:07.593229700Z"
    }
   },
   "id": "4b0b70f16ea958b1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def display(image, size=8):\n",
    "    print(image[0].shape)\n",
    "    image = image[0].permute((1, 2, 0))\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:07.903981100Z",
     "start_time": "2023-11-27T23:30:07.878981200Z"
    }
   },
   "id": "f6403a2595f0aea8"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[14])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:07.950981700Z",
     "start_time": "2023-11-27T23:30:07.893980800Z"
    }
   },
   "id": "eaed33a246824db1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split a batch of data into batch of patches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "465cffcc2714f724"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:07.965982200Z",
     "start_time": "2023-11-27T23:30:07.942982200Z"
    }
   },
   "id": "369ba5d45a1b4be"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def batch_patch(tensor, step=4):\n",
    "    if len(tensor.shape) == 3:\n",
    "        return (\n",
    "            tensor.unfold(0, 3, 3)\n",
    "            .unfold(1, step, step)\n",
    "            .unfold(2, step, step)\n",
    "            .flatten(start_dim=0, end_dim=2)\n",
    "        )\n",
    "    return (\n",
    "        tensor.unfold(1, 3, 3)\n",
    "        .unfold(2, step, step)\n",
    "        .unfold(3, step, step)\n",
    "        .squeeze()\n",
    "        .flatten(start_dim=1, end_dim=2)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.037981300Z",
     "start_time": "2023-11-27T23:30:07.957980800Z"
    }
   },
   "id": "fc9a852d8ac38345"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1f14e7ced70>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = next(iter(data_loader))[0]\n",
    "\n",
    "step = 4\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(\n",
    "    (\n",
    "        vutils.make_grid(\n",
    "            batch_patch(d, step)[0], nrow=32 // step, padding=1, normalize=True\n",
    "        )\n",
    "        .permute(1, 2, 0)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.038981200Z",
     "start_time": "2023-11-27T23:30:07.974981400Z"
    }
   },
   "id": "6d34b5fd5ea80488"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e62f272b295fbb17"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.053981700Z",
     "start_time": "2023-11-27T23:30:08.036981100Z"
    }
   },
   "id": "4367f5eb69f307e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First implement the learnable positional encoding layer - it was used in DDPM lab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f785d80b1d212b0b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, input_size=65, d=25, n=10000, output_size=256):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        denominator = torch.pow(n, torch.arange(d) / d)\n",
    "        numerator = torch.arange(input_size).reshape(-1, 1)\n",
    "        self.inputs = torch.concat(\n",
    "            [torch.sin(numerator / denominator), torch.cos(numerator / denominator)], 1\n",
    "        ).to(device)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2 * d, out_features=output_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=output_size, out_features=output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, k):\n",
    "        return self.network(self.inputs[k])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.105980900Z",
     "start_time": "2023-11-27T23:30:08.055982Z"
    }
   },
   "id": "a1b0a49648cf48b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a transformer block - We'll need a few of them so it's easier to make a separate class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3349943544c2b8f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_dims=256, n_heads=8):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(n_dims)\n",
    "        self.attention = nn.MultiheadAttention(n_dims, n_heads)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.LayerNorm(n_dims),\n",
    "            nn.Linear(n_dims, 2 * n_dims),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2 * n_dims, n_dims),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        post_norm = self.norm(input)\n",
    "        post_attention = self.attention(post_norm, post_norm, post_norm)[0] + input\n",
    "        return self.network(post_attention) + post_attention"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.106983Z",
     "start_time": "2023-11-27T23:30:08.068981400Z"
    }
   },
   "id": "a0c0b2525e1a83cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whole model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cd89879c2ced40b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class VisionTransformerModel(nn.Module):\n",
    "    def __init__(self, n_classes, patch_size=4, im_size=32, n_dims=256):\n",
    "        super(VisionTransformerModel, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.token = nn.Parameter(\n",
    "            torch.zeros(256, dtype=torch.float32), requires_grad=True\n",
    "        ).to(device)\n",
    "        self.positional_embedding_keys = torch.arange((im_size // patch_size) ** 2 + 1)\n",
    "        self.patch_flatten = nn.Flatten(start_dim=-3)\n",
    "        self.embed = nn.Linear(3 * patch_size**2, n_dims)\n",
    "        self.positional_encode = PositionalEncoding(input_size=n_dims, output_size=256)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.transformers = nn.Sequential(\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "        ).to(device)\n",
    "        self.normalization = nn.LayerNorm(n_dims)\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(256, 2 * n_dims),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2 * n_dims, n_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        patched = batch_patch(img, self.patch_size)\n",
    "        flattened = self.patch_flatten(patched)\n",
    "        embedded = self.embed(flattened)\n",
    "\n",
    "        class_token = torch.ones(img.shape[0]).to(device).reshape(-1, 1, 1) * self.token\n",
    "        with_token = torch.concat([class_token, embedded], 1)\n",
    "\n",
    "        with_encode = with_token + self.positional_encode(\n",
    "            self.positional_embedding_keys\n",
    "        )\n",
    "\n",
    "        tr = self.dropout1(with_encode)\n",
    "        tr = self.transformers(tr)[:, 0]\n",
    "        normalized = self.normalization(tr)\n",
    "        return self.MLP(normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.107980900Z",
     "start_time": "2023-11-27T23:30:08.084980700Z"
    }
   },
   "id": "42d2eb72a01a9dd3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare the model for training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3379bcd0be342b6a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model = VisionTransformerModel(len(data.classes)).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.227981Z",
     "start_time": "2023-11-27T23:30:08.100980900Z"
    }
   },
   "id": "b9991d03b14aacff"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100, 150], 0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:30:08.242981600Z",
     "start_time": "2023-11-27T23:30:08.227981Z"
    }
   },
   "id": "59467a0864c1d81c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      " - loss: 2.3028831481933594\n",
      "epoch: 1\n",
      " - loss: 2.302767276763916\n",
      "epoch: 2\n",
      " - loss: 2.3024747371673584\n",
      "epoch: 3\n",
      " - loss: 2.3027334213256836\n",
      "epoch: 4\n",
      " - loss: 2.302345037460327\n",
      "epoch: 5\n",
      " - loss: 2.3025853633880615\n",
      "epoch: 6\n",
      " - loss: 2.3026578426361084\n",
      "epoch: 7\n",
      " - loss: 2.302765130996704\n",
      "epoch: 8\n",
      " - loss: 2.302555799484253\n",
      "epoch: 9\n",
      " - loss: 2.3025734424591064\n",
      "epoch: 10\n",
      " - loss: 2.302577495574951\n",
      "epoch: 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch:\u001B[39m\u001B[38;5;124m\"\u001B[39m, epoch)\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(data_loader):\n\u001B[0;32m      6\u001B[0m     iteration \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      7\u001B[0m     total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    115\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    121\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001B[0m, in \u001B[0;36mNormalize.forward\u001B[1;34m(self, tensor)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    270\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    271\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;124;03m        Tensor: Normalized Tensor image.\u001B[39;00m\n\u001B[0;32m    276\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001B[0m, in \u001B[0;36mnormalize\u001B[1;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tensor, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m    361\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg should be Tensor Image. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(tensor)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 363\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_t\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001B[0m, in \u001B[0;36mnormalize\u001B[1;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[0;32m    920\u001B[0m mean \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(mean, dtype\u001B[38;5;241m=\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mtensor\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    921\u001B[0m std \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(std, dtype\u001B[38;5;241m=\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mtensor\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43m(\u001B[49m\u001B[43mstd\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43many\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    923\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstd evaluated to zero after conversion to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, leading to division by zero.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    924\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mean\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(160):\n",
    "    iteration = 0\n",
    "    total_loss = 0\n",
    "    print(\"epoch:\", epoch)\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        iteration = 0\n",
    "        total_loss = 0\n",
    "        batch_data = batch[0].to(device)\n",
    "        batch_labels = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch_data)\n",
    "        loss = loss_fn(pred, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        iteration += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\" - loss:\", total_loss.item() / iteration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:35:06.400516500Z",
     "start_time": "2023-11-27T23:30:08.244981300Z"
    }
   },
   "id": "cb530baee34620f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:35:06.403517400Z",
     "start_time": "2023-11-27T23:35:06.403517400Z"
    }
   },
   "id": "c9680434b2f874c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(100 * correct / total, \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T23:35:06.404515Z",
     "start_time": "2023-11-27T23:35:06.403517400Z"
    }
   },
   "id": "785a6df7cf23bddb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = next(iter(test_loader))[0][:16].to(device)\n",
    "\n",
    "classification = torch.argmax(model(d), 1)\n",
    "\n",
    "for c in classification:\n",
    "    print(classes[c])\n",
    "\n",
    "step = 4\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(\n",
    "    (\n",
    "        vutils.make_grid(d, nrow=4, padding=1, normalize=True)\n",
    "        .permute(1, 2, 0)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T23:35:06.405517Z"
    }
   },
   "id": "6fd2ac6a5ab13d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T23:35:06.406515400Z"
    }
   },
   "id": "ee75a18f87960a2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
