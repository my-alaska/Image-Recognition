{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:36.567910600Z",
     "start_time": "2023-11-28T12:40:36.492911300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(cuda_id)\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:36.615910700Z",
     "start_time": "2023-11-28T12:40:36.509910700Z"
    }
   },
   "id": "e8a100858fc8b50b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download and preparethe data\n",
    "\n",
    "We'll use the CIFAR10 dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f51fdad69ce1e7a6"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:36.666910700Z",
     "start_time": "2023-11-28T12:40:36.525911600Z"
    }
   },
   "id": "86e29a36b84c2248"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "batch_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:36.667911400Z",
     "start_time": "2023-11-28T12:40:36.541911400Z"
    }
   },
   "id": "bf8b0e5f6d01c396"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# download and augment the training dataset\n",
    "if not os.path.exists(\"./data\"):\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "data = CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomResizedCrop(size=32, ratio=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0, 1),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0, 1),\n",
    "        ]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "test_loader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.734225100Z",
     "start_time": "2023-11-28T12:40:36.558910700Z"
    }
   },
   "id": "8ddb240309e17171"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "['airplane',\n 'automobile',\n 'bird',\n 'cat',\n 'deer',\n 'dog',\n 'frog',\n 'horse',\n 'ship',\n 'truck']"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = data.classes\n",
    "classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.758225800Z",
     "start_time": "2023-11-28T12:40:37.735225500Z"
    }
   },
   "id": "a2cc10088ac10168"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print out an example image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2277894ab71e829"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.797225100Z",
     "start_time": "2023-11-28T12:40:37.751228300Z"
    }
   },
   "id": "4b0b70f16ea958b1"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "def display(image, size=8):\n",
    "    print(image[0].shape)\n",
    "    image = image[0].permute((1, 2, 0))\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.799227900Z",
     "start_time": "2023-11-28T12:40:37.767225400Z"
    }
   },
   "id": "f6403a2595f0aea8"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[14])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.877225200Z",
     "start_time": "2023-11-28T12:40:37.784225700Z"
    }
   },
   "id": "eaed33a246824db1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split a batch of data into batch of patches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "465cffcc2714f724"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.889225500Z",
     "start_time": "2023-11-28T12:40:37.830225600Z"
    }
   },
   "id": "369ba5d45a1b4be"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def batch_patch(tensor, step=4):\n",
    "    if len(tensor.shape) == 3:\n",
    "        return (\n",
    "            tensor.unfold(0, 3, 3)\n",
    "            .unfold(1, step, step)\n",
    "            .unfold(2, step, step)\n",
    "            .flatten(start_dim=0, end_dim=2)\n",
    "        )\n",
    "    return (\n",
    "        tensor.unfold(1, 3, 3)\n",
    "        .unfold(2, step, step)\n",
    "        .unfold(3, step, step)\n",
    "        .squeeze()\n",
    "        .flatten(start_dim=1, end_dim=2)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.890225300Z",
     "start_time": "2023-11-28T12:40:37.848225500Z"
    }
   },
   "id": "fc9a852d8ac38345"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x24a11339f60>"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = next(iter(data_loader))[0]\n",
    "\n",
    "step = 4\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(\n",
    "    (\n",
    "        vutils.make_grid(\n",
    "            batch_patch(d, step)[0], nrow=32 // step, padding=1, normalize=True\n",
    "        )\n",
    "        .permute(1, 2, 0)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.933225400Z",
     "start_time": "2023-11-28T12:40:37.863225300Z"
    }
   },
   "id": "6d34b5fd5ea80488"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e62f272b295fbb17"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.952226200Z",
     "start_time": "2023-11-28T12:40:37.926225800Z"
    }
   },
   "id": "4367f5eb69f307e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First implement the learnable positional encoding layer - it was used in DDPM lab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f785d80b1d212b0b"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, input_size=65, d=25, n=10000, output_size=256):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        denominator = torch.pow(n, torch.arange(d) / d)\n",
    "        numerator = torch.arange(input_size).reshape(-1, 1)\n",
    "        self.inputs = torch.concat(\n",
    "            [torch.sin(numerator / denominator), torch.cos(numerator / denominator)], 1\n",
    "        ).to(device)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2 * d, out_features=output_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=output_size, out_features=output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, k):\n",
    "        return self.network(self.inputs[k])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.987225100Z",
     "start_time": "2023-11-28T12:40:37.943226600Z"
    }
   },
   "id": "a1b0a49648cf48b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a transformer block - We'll need a few of them so it's easier to make a separate class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3349943544c2b8f"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_dims=256, n_heads=8):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(n_dims)\n",
    "        self.attention = nn.MultiheadAttention(n_dims, n_heads)\n",
    "        self.network = nn.Sequential(\n",
    "            nn.LayerNorm(n_dims),\n",
    "            nn.Linear(n_dims, 2 * n_dims),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2 * n_dims, n_dims),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        residual = input\n",
    "        out = self.norm(input)\n",
    "        out = self.attention(out, out, out)[0] \n",
    "        out += residual\n",
    "        residual2 = out\n",
    "        out = self.network(out)\n",
    "        out += residual2\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.987225100Z",
     "start_time": "2023-11-28T12:40:37.958225600Z"
    }
   },
   "id": "a0c0b2525e1a83cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whole model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cd89879c2ced40b"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "class VisionTransformerModel(nn.Module):\n",
    "    def __init__(self, n_classes, patch_size=4, im_size=32, n_dims=256):\n",
    "        super(VisionTransformerModel, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.token = torch.zeros(256, dtype=torch.float32,requires_grad=True,device=device)\n",
    "        self.positional_embedding_keys = torch.arange((im_size // patch_size) ** 2 + 1)\n",
    "        self.patch_flatten = nn.Flatten(start_dim=-3)\n",
    "        self.embed = nn.Linear(3 * patch_size**2, n_dims)\n",
    "        self.positional_encode = PositionalEncoding(input_size=n_dims, output_size=256)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.transformers = nn.Sequential(\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "            TransformerBlock(n_dims=n_dims),\n",
    "        ).to(device)\n",
    "        self.normalization = nn.LayerNorm(n_dims)\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(n_dims, 2 * n_dims),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2 * n_dims, n_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        patched = batch_patch(img, self.patch_size)\n",
    "        flattened = self.patch_flatten(patched)\n",
    "        embedded = self.embed(flattened)\n",
    "\n",
    "        class_token = torch.ones(img.shape[0]).to(device).reshape(-1, 1, 1) * self.token\n",
    "        with_token = torch.concat([class_token, embedded], 1)\n",
    "\n",
    "        encoding = self.positional_encode(self.positional_embedding_keys)\n",
    "        with_encode = with_token + encoding\n",
    "\n",
    "        tr = self.dropout1(with_encode)\n",
    "        tr = self.transformers(tr)[:, 0]\n",
    "        normalized = self.normalization(tr)\n",
    "        return self.MLP(normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:37.988225500Z",
     "start_time": "2023-11-28T12:40:37.976225300Z"
    }
   },
   "id": "42d2eb72a01a9dd3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare the model for training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3379bcd0be342b6a"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "model = VisionTransformerModel(len(data.classes)).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:38.066226500Z",
     "start_time": "2023-11-28T12:40:37.989225100Z"
    }
   },
   "id": "b9991d03b14aacff"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "'attached.png'"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "x = Variable(torch.rand((2,3,32,32)).to(device), requires_grad=True)\n",
    "y = model(x)\n",
    "\n",
    "make_dot(y).render(\"attached\", format=\"png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:38.821446300Z",
     "start_time": "2023-11-28T12:40:38.067225800Z"
    }
   },
   "id": "2a6e20c09c207772"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters()] + [model.token]\n",
    "optimizer = torch.optim.AdamW(params, lr=0.001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100, 150], 0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:38.863446100Z",
     "start_time": "2023-11-28T12:40:38.818447200Z"
    }
   },
   "id": "59467a0864c1d81c"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "labels = nn.functional.one_hot(\n",
    "    torch.tensor([i for i in range(len(data.classes))]), num_classes=len(classes)\n",
    ").detach()\n",
    "labels = torch.as_tensor(labels,dtype=torch.float32,device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:40:38.875446600Z",
     "start_time": "2023-11-28T12:40:38.833447400Z"
    }
   },
   "id": "352c376ed5933b8a"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      " - loss: 2.3026397228240967\n",
      "epoch: 1\n",
      " - loss: 2.3027589321136475\n",
      "epoch: 2\n",
      " - loss: 2.3026537895202637\n",
      "epoch: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[129], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch:\u001B[39m\u001B[38;5;124m\"\u001B[39m, epoch)\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m data_loader:\n\u001B[0;32m      6\u001B[0m     iteration \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      7\u001B[0m     total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    115\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    121\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:720\u001B[0m, in \u001B[0;36mRandomHorizontalFlip.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    712\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    713\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    714\u001B[0m \u001B[38;5;124;03m    img (PIL Image or Tensor): Image to be flipped.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;124;03m    PIL Image or Tensor: Randomly flipped image.\u001B[39;00m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    719\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp:\n\u001B[1;32m--> 720\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhflip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:667\u001B[0m, in \u001B[0;36mhflip\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m    663\u001B[0m     img \u001B[38;5;241m=\u001B[39m resize(img, size, interpolation, antialias\u001B[38;5;241m=\u001B[39mantialias)\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n\u001B[1;32m--> 667\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhflip\u001B[39m(img: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    668\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Horizontally flip the given image.\u001B[39;00m\n\u001B[0;32m    669\u001B[0m \n\u001B[0;32m    670\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor:  Horizontally flipped image.\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_tracing():\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(160):\n",
    "    iteration = 0\n",
    "    total_loss = 0\n",
    "    print(\"epoch:\", epoch)\n",
    "    for batch in data_loader:\n",
    "        iteration = 0\n",
    "        total_loss = 0\n",
    "        batch_data = batch[0].to(device)\n",
    "        batch_labels = labels[batch[1]]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch_data)\n",
    "        loss = loss_fn(pred, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        iteration += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\" - loss:\", total_loss.item() / iteration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T12:41:32.849211800Z",
     "start_time": "2023-11-28T12:40:38.850446400Z"
    }
   },
   "id": "cb530baee34620f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T12:41:32.843211600Z"
    }
   },
   "id": "c9680434b2f874c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(100 * correct / total, \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T12:41:32.845211200Z"
    }
   },
   "id": "785a6df7cf23bddb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = next(iter(test_loader))[0][:16].to(device)\n",
    "\n",
    "classification = torch.argmax(model(d), 1)\n",
    "\n",
    "for c in classification:\n",
    "    print(classes[c],end = \" \")\n",
    "\n",
    "step = 4\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(\n",
    "    (\n",
    "        vutils.make_grid(d, nrow=4, padding=1, normalize=True)\n",
    "        .permute(1, 2, 0)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T12:41:32.846211100Z"
    }
   },
   "id": "6fd2ac6a5ab13d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T12:41:32.847211200Z"
    }
   },
   "id": "ee75a18f87960a2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
