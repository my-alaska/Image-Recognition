{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# look mom no numpy!\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6e79f31b23eb43db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "with open(\"bicycle.txt\") as bicycle:\n",
    "    for line in bicycle:\n",
    "        row = line.split()\n",
    "        x.append(float(row[0]))\n",
    "        y.append(float(row[1]))\n",
    "\n",
    "data = tf.convert_to_tensor(list(zip(x, y)))\n",
    "print(data[500:510])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "eb0035ebfbfd6d6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2-dimensional distribution of data - target distribution we'll try to approximate\n",
    "# colorful image of dimensions 32x32x3 will be considered as one point of similar distribution. except 3072-dimensional\n",
    "plt.scatter(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2234b9fd1ca862d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's try to add noise to each point"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c9d2a0de881e00a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_steps = 1000  # number of noiseadding steps"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3966770fbf1de2e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# parameters\n",
    "betas = tf.linspace(0.0001, 0.02, n_steps)\n",
    "alphas = 1 - betas\n",
    "alpha_prods = tf.math.cumprod(alphas)\n",
    "plt.plot(alpha_prods)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ff628a21833e44f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This method falls down to zero too quickly. We need another one\n",
    "# turns out if we swap the range to"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a4baca9d013ae042"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "steps = (tf.range(0, n_steps, dtype=tf.float32) - n_steps / 2) / 100\n",
    "betas = tf.exp(steps) / (1 + tf.exp(steps))\n",
    "betas = betas * 0.0101188381035  # value chosen by trial and error :)\n",
    "alphas = 1 - betas\n",
    "alpha_prods = tf.math.cumprod(alphas)\n",
    "print(alpha_prods[500])\n",
    "plt.plot(alpha_prods)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ec240a99c957d562"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# adding noise to the data"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "432539cb26e2937d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I = tf.eye(2)\n",
    "N = len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "86f90b7409ac865f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate noise for the whole dataset and all iterations\n",
    "noises = tf.random.normal(shape=(n_steps, N, 2)) * tf.reshape(\n",
    "    (1 - alpha_prods), (n_steps, 1, 1)\n",
    ")\n",
    "noises.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a1b7e5a692a85163"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate noise for the \"i\"th iteration for a group of size 64\n",
    "n = 64  # number of elements to noise\n",
    "t = 37  # number of iteration\n",
    "(tf.random.normal(shape=(n, 2)) * (1 - alpha_prods[t])).shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5578f1658a155a0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate new means for all iterations\n",
    "data_means = data * tf.reshape(tf.sqrt(alpha_prods), (1000, 1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "be102b822b4c4de4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate a mean for a given iteration for a specific part of the dataset\n",
    "n = 64\n",
    "t = 37\n",
    "start = 58\n",
    "(data[start : start + n] * tf.sqrt(alpha_prods[t])).shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bec369eb47d87a53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate all iterations\n",
    "iterations = noises + data_means\n",
    "# iterations = tf.reshape(iterations,iterations.shape[:2] + [1] + iterations.shape[2])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c0431806ea191cd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function to noise fiven points in a given iteration\n",
    "\n",
    "\n",
    "def noise(points, t):\n",
    "    return points * tf.sqrt(alpha_prods[t]) + tf.random.normal(shape=points.shape) * (\n",
    "        1 - alpha_prods[t]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "53186487976c3d86"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(10, figsize=(5, 50))\n",
    "\n",
    "for i in range(10):\n",
    "    d = noise(data, i * 100)\n",
    "    # axis[i].scatter(iterations[i*100,:,:,0],iterations[i*100,:,:,1],marker=\".\",s=1)\n",
    "    axis[i].scatter(d[:, 0], d[:, 1], marker=\".\", s=1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9faf180db63d3993"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build a diffusion model\n",
    "\n",
    "### Create a Learnable Sinusoidal Embedding block"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba30c89b1d3d38a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LearnableSinusoidalEmbedding(layers.Layer):\n",
    "    def __init__(self, d=25, n=10000, output_size=128):\n",
    "        super(LearnableSinusoidalEmbedding, self).__init__()\n",
    "        self.d = d\n",
    "        self.denominator = tf.cast(tf.math.pow(n, tf.range(d) / d), tf.float32)\n",
    "        self.dense1 = layers.Dense(128, input_shape=(2 * d,), activation=\"relu\")\n",
    "        self.dense2 = layers.Dense(output_size, input_shape=(128,))\n",
    "\n",
    "    def call(self, k):\n",
    "        k = tf.reshape(k, (-1, tf.shape(k)[0]))\n",
    "        k = tf.transpose(k)\n",
    "        # values of cosine and sine can be permuted however we want as we're feeding them to dense layers\n",
    "        input = tf.concat(\n",
    "            [tf.sin(k / self.denominator), tf.cos(k / self.denominator)], 1\n",
    "        )\n",
    "        output1 = self.dense1(input)\n",
    "        return self.dense2(output1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "136ff25a2b1b796a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lse = LearnableSinusoidalEmbedding(25)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "89ac574c3f250892"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lse(steps[:3]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c735f1f4ed28b9dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a Conditional Dense Layer block"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99e78f8bf2953f1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConditionalDenseLayer(layers.Layer):\n",
    "    def __init__(self, d=25, n=10000, output_size=128, relu=True):\n",
    "        super(ConditionalDenseLayer, self).__init__()\n",
    "        self.lse = LearnableSinusoidalEmbedding(d, n, output_size)\n",
    "        self.dense = layers.Dense(output_size)\n",
    "        self.relu = relu\n",
    "\n",
    "    def call(self, point, t):\n",
    "        tensor = self.lse(t) + self.dense(point)\n",
    "        if self.relu:\n",
    "            return tf.keras.activations.relu(tensor)\n",
    "        else:\n",
    "            return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bedb1f34a07ce494"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.cast(2, tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "587406ff57546099"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cdl = ConditionalDenseLayer()\n",
    "cdl_output_1 = cdl(tf.cast(iterations[:64, 0], tf.float32), steps[:64])\n",
    "cdl_output_1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f39594cc6d8af6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cdl_out = ConditionalDenseLayer(output_size=2, relu=False)\n",
    "cdl_out(cdl_output_1, tf.cast([2], tf.float32)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b056fa67e876524e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a neural network that will learn to approximate the distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943c79f7d0958600"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first way. Looks like pytorch wow I hate my coding style\n",
    "class DiffusionNetwork(layers.Layer):\n",
    "    def __init__(self, d=25, n=10000):\n",
    "        super(DiffusionNetwork, self).__init__()\n",
    "        self.cdl1 = ConditionalDenseLayer(d, n)\n",
    "        self.cdl2 = ConditionalDenseLayer(d, n)\n",
    "        self.cdl3 = ConditionalDenseLayer(d, n)\n",
    "        self.cdl4 = ConditionalDenseLayer(d, n, output_size=2, relu=False)\n",
    "\n",
    "    def call(self, inp):\n",
    "        point, t = inp[0], inp[1]\n",
    "        data = self.cdl1(point, t)\n",
    "        data = self.cdl2(data, t)\n",
    "        data = self.cdl3(data, t)\n",
    "        return self.cdl4(data, t)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c624bc9eb9172ef2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# another way. Much batter. Maybe... A little? No I don't know. Still a mix of torch and tf\n",
    "def get_network(d=25, n=10000):\n",
    "    cdl1 = ConditionalDenseLayer(d, n)\n",
    "    cdl2 = ConditionalDenseLayer(d, n)\n",
    "    cdl3 = ConditionalDenseLayer(d, n)\n",
    "    cdl4 = ConditionalDenseLayer(d, n, output_size=2, relu=False)\n",
    "\n",
    "    point_input = layers.Input(shape=(2,), name=\"point_input\")\n",
    "    time_input = layers.Input(shape=(1,), name=\"time_input\")\n",
    "    out1 = cdl1(point_input, time_input)\n",
    "    out2 = cdl2(out1, time_input)\n",
    "    out3 = cdl3(out2, time_input)\n",
    "    out4 = cdl4(out3, time_input)\n",
    "\n",
    "    return keras.Model([point_input, time_input], out4)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5f6f10573e9b829"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "network = get_network()\n",
    "network([data[:64], steps[:64]]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6917936694e093ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diffusion_net = DiffusionNetwork()\n",
    "diffusion_net([data[:64], steps[:64]]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b26375fddc7d2a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assemble the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6dce2d171f9e18d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DiffusionModel(keras.Model):\n",
    "    def __init__(self, network, n_steps):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        steps = (tf.range(0, n_steps, dtype=tf.float32) - n_steps / 2) / 100\n",
    "        betas = tf.exp(steps) / (1 + tf.exp(steps))\n",
    "        self.betas = betas * 0.0101188381035  # value chosen by trial and error :)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.n_steps = n_steps\n",
    "        self.alpha_prods = tf.math.cumprod(alphas)\n",
    "\n",
    "    def train_step(self, points):\n",
    "        t = tf.random.uniform(\n",
    "            minval=0, maxval=self.n_steps, shape=tf.shape(points)[:1], dtype=tf.int64\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            noise = tf.random.normal(shape=tf.shape(points))\n",
    "            points_t = (\n",
    "                points * tf.sqrt(tf.gather(self.alpha_prods, t))[..., None]\n",
    "                + noise * tf.sqrt(1 - tf.gather(self.alpha_prods, t))[..., None]\n",
    "            )\n",
    "            pred_noise = self.network([points_t, t], training=True)\n",
    "            loss = self.loss(noise, pred_noise)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def generate_diffusion(self, points):\n",
    "        result = []\n",
    "        for t in range(n_steps - 1, -1, -1):\n",
    "            if t == 0:\n",
    "                z = 0\n",
    "            else:\n",
    "                z = tf.random.normal(shape=points.shape)\n",
    "            points = (\n",
    "                points\n",
    "                - self.network([points, tf.cast([[t]], tf.float32)])\n",
    "                * (1 - alphas[t])\n",
    "                / tf.sqrt(1 - alpha_prods[t])\n",
    "            ) / tf.sqrt(alphas[t]) + z * tf.sqrt(betas[t])\n",
    "            if t % 100 == 0:\n",
    "                result.append(points)\n",
    "        result.append(points)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "15ddab3aad7593e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DiffusionModel(get_network(), n_steps)\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d3a768a792e01641"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=data,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5d17cb74c72bbace"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normal_input = tf.random.normal(shape=(50000, 2))\n",
    "predictions = model.generate_diffusion(normal_input)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "12fc7637b6bf771d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(len(predictions), figsize=(5, 6 * len(predictions)))\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    d = predictions[i]\n",
    "    axis[i].scatter(d[:, 0], d[:, 1], marker=\".\", s=1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a5795568db9c53e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5df37edf4f9f0b54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
